{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRED 420-56 Winter 2016 GrEx1 Comments and Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice effort, collectively speaking.  By and large you all did quite well on this one.  \n",
    "\n",
    "The average score was 71.4 out of a possible 75.\n",
    "\n",
    "Some comments and examples follow.  Any code should be Python 2.7+ compatible, but perhaps not Python 3.x compatible. (A Canopy concession.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you turned in your assignment late, I cut you some slack if it wasn't _too_ late.  Be aware that going forward you'll be penalized for late work as indicated in the syllabus. \n",
    "\n",
    "Some have asked why we penalize late work in MSPA courses.  One reason is that when folks turn in their work late it slows a course down.  Another is that it's unfair to those who get their work turned in on time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay Attention to  the Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the most points on an assignment, you need to do exactly what it asks you to do, how it asks you to do it. It's not enough just to accomplish what the assignment asks you to do.\n",
    "\n",
    "For example, on this assignment some of you read the data in the csv files into Python using Python's csv module.  This got the data into Python, but note that the assignment specifically asked that you use pandas to read the files. \n",
    "\n",
    "The assignment asked that you explain each line of your code.  This includes code you used to answer questions asked, like the three questions at the end of the assignment description.  No harm no foul this time, but bear in mind that for future assigments you should include the code you used to answer each question, and that you should explain each line of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels for Dataframe Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you created your column labels in Python, and wrote them out to csv files that you then read back into Python.  Given that there weren't many columns needing column names, wouldn't it have been easier to just use an editor to type your labels into csv files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About those \\N's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The person or people who compiled the data files decided to use the string \\N to indicate a missing value.  Do you look to see if there are any in the data, and if so, where?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarity and Transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to remember about using Python is the high priority put on code readability and maintainability.  See, for example:\n",
    "\n",
    "[Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008)\n",
    "\n",
    "A key concept is that you and others should be able to read and understand your code.  Bear this in mind as you write up your assignments.  (It's also important that I be able to read and interpret your code, of course.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"with\" idiom for Automatic File Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you wrote and read from files using separate open and close statements.  In general it's wise to close all things you open.  \n",
    "\n",
    "If you do something like:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('myData.dat') as myInput:\n",
    "    varData=myInput.read()\n",
    "    # optionally do stuff with varData here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the file `myData.dat` will be closed automatically for you once input from it is done.\n",
    "\n",
    "Here's a (somewhat) clear (and rather old) explanation of `with`:\n",
    "\n",
    "[Explanation of the With Statement](http://effbot.org/zone/python-with-statement.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Common Missteps and Oddities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opening a file but then not actually reading from it.\n",
    "* Opening a file and then not closing it.\n",
    "* Reading a csv file without a header record into a DataFrame with pd.read_csv without indicating that the file has no header record by using for example the option header=None.  \n",
    "-- Doing this with a csv file containing pd DataFrame column names in a single record results in a DataFrame without any data that has column names.   But this can actually work for the purpose of getting column names for another DataFrame into Python. Can you think of how this might work?\n",
    "* Interpreting the last of those three questions at the end of the assignment as having to do with the airport closest to home.  It only had to do with the number of routes with EGO as their destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Your Code in Upcoming Graded Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will serve you best in terms of the points you get is to explain each line of your code.   You can do this using the various ways that the comment marker # can be applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting PDF from a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be gnarly to do, depending on your version of jupyter and on the OS you're running.  I find that I can reliably convert notebooks to pdf using the jupyter nbconvert commands on the command line of a terminal session.   Notebook in the version of Canopy I'm running on 64 bit Linux can render a pdf.  Notebook in my Anaconda and Anaconda 3 versions can't.  But I can convert a notebook to a pdf file using either one of them if I use jupyter nbconvert {notebook file} {options} from a terminal command prompt, where {options} are the conversion options, and {notebook file} is the name of the notebook file to be converted from .ipynb to .pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The First of THose Last Three Questions: the Airport Closest to Your Home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could guess at which airport is closest to your home, and you might be correct. But the data include many airports.  To be as certain as possible about the closest to you, you'd need to use the data.   I didn't expect that most of you would do this.  But, a number of you did!  You'll have a chance to work on a similar question for extra credit in GrEx2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment asked you to create a text file of field names for each input data set.  Each of these was to be a one record file with names separated by commas.  The simplest way to do this was to use a text editor to create each file.  Just type the names into one record, separated by commas.\n",
    "\n",
    "You were then asked to read each of your field names into Python and to use them as column names in your pandas DataFrames.   You could have done this in a couple of ways.  You could use the csv package in Python.  For example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import the csv package into this session\n",
    "import csv\n",
    "import pandas as pd\n",
    "# all files are in the current working directory\n",
    "#\n",
    "# read the field names to be used as DataFrame column names\n",
    "with open('airlinelabs.csv') as labsIn:  # the defaults work ok here\n",
    "    airlabs=list(csv.reader(labsIn))     # reading just one row of data into a list\n",
    "  \n",
    "    \n",
    "\"\"\" \n",
    "You'll note that airlabs will be a list containing a list. Or, a list with one element that is a list. But, magically, you can still use it to label columns in a DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "# get the airlines data into a pandas DataFrame:\n",
    "airlinesDF=pd.read_csv('airlines.dat', header=None)  \n",
    "\n",
    "airlinesDf.columns=airlabs   # It really works! But using =airlabs[0] will give you the same result, as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you could use read_csv() in pandas:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "airlabs=pd.read_csv('airlinelabs.csv', header=None)  # get a DataFrame with one row of data from a file w/o a header\n",
    "\n",
    "airlinesDF.columns=airlabs.loc[0]       # The column names are in the first (and only) row of data in airlabs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You were asked a couple of questions about numbers of routes.  Both could be answered by filtering or selecting records in your routes DataFrame using the code for the airport in question.   Suppose that routesDF is a pandas DataFrame with the routes.dat data in it.  In this DataFrame, souceAp is the name of the column of source (or route origin) airport codes, and destAp is the column of destination airport codes.   Suppose that my nearest airport is BHM (this is a guess; I haven't checked for other airports that are geographically closer), then I can find out how many departing routes there are from BHM by counting how many records there are in routesDF that have sourceAp equal to BHM:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "routesDF[routesDF.sourceAp==\"BHM\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a tuple that's (number of rows, number of columns) for the DataFrame that has only records with sourceAp equal to BHM. Here it will be (36,9).  We're assuming here that the data is correct, of course, i.e. no miscodes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question about EGO routes can be answered similarly:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "routesDF[routesDF.destAp==\"EGO\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11,9), right?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
